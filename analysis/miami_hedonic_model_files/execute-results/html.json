{
  "hash": "6c2825ea67de6a4a69b2bfc8f0d3eb2a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predicting Miami Home Prices\"\nauthor: \"Anna Duan and Bingchu Chen\"\ndate: \"10/16/2020\"\ncategories: [R, Housing, Prediction]\nformat: \n  html:\n    toc: true\n    code-fold: true\n    fontsize: 11pt\nexecute:\n  echo: true\n---\n\n\n## Introduction\nAccurate prediction of home sale prices is important right now as the real estate market is seeing record levels of activity due to the pandemic. In this report, we construct a new hedonic model for Zillow's housing market predictions. This task is challenging due to the number of factors which affect the real estate market and the non-linear relationship between many factors and prices. In this model which is built for Miami and Miami Beach, we incorporate local intelligence from open sourced data to adapt it to local housing and development patterns. We use determinants of home prices including internal characteristics, nearby amenities and dis-amenities, and spatial processes such as clustering to estimate home sale prices. Applying this model to a set of 3503 houses, it predicted that home sale prices are highest on the shoreline and in Miami Beach.\n\n\n\n\n\n\n## Data\nFor this analysis, we received a dataset of houses and their internal characteristics including number of rooms, living area, and pools. In addition, we gathered open-sourced data from the American Community Survey, Miami Dade County's Open Data Hub, OpenStreetMaps. This includes  census-tract level demographic information and point and polygon layers of amenities including restaurants and parks (Table 1). It is expected that attributes that contribute to quality of life such as proximity to restaurants, park space, and low commuting times correlate positively with sale prices. \n\n::: {.cell}\n\n```{.r .cell-code}\n#projected to NAD 1983 StatePlane Florida East FIPS 0901 Feet\n\n#STUDY AREA\nmiamiBound <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/Municipal_Boundary.geojson\") %>%\n  filter(NAME == \"MIAMI BEACH\" | NAME == \"MIAMI\") %>%\n  st_make_valid() %>%\n  st_union() %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n\n\n\n#STUDY AREA OSM (not projected so that it works)\n#miamiBoundOSM <- st_read(\"E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/Municipal_Boundary.geojson\") %>%\nmiamiBoundOSM <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/Municipal_Boundary.geojson\") %>%\n  filter(NAME == \"MIAMI BEACH\" | NAME == \"MIAMI\") %>%\n  st_make_valid() %>%\n  st_union()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#HOUSE DATA\n#houses <- st_read(\"E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/studentsData.geojson\") %>%\nhouses <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/studentsData.geojson\") %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658') %>%\n  st_centroid()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `studentsData' from data source \n  `/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw Data/studentsData.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 3503 features and 58 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.31756 ymin: 25.70911 xmax: -80.12061 ymax: 25.87091\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nhouses_train <- houses %>%\n  filter(toPredict == 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#HOUSE DATA OSM (Not projected)\n#housesOSM <- st_read(\"E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/studentsData.geojson\")\nhousesOSM <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/studentsData.geojson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `studentsData' from data source \n  `/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw Data/studentsData.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 3503 features and 58 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.31756 ymin: 25.70911 xmax: -80.12061 ymax: 25.87091\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#CENSUS\ncensus_api_key(\"d9ebfd04caa0138647fbacd94c657cdecbf705e9\", install = TRUE, overwrite = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"d9ebfd04caa0138647fbacd94c657cdecbf705e9\"\n```\n\n\n:::\n\n```{.r .cell-code}\n#read in: vacant property, total housing units, mhhinc, white, population, owner occ, renter occ, travel time to work\nacs <-\n  get_acs(geography = \"tract\", variables = c(\"B25002_003E\", \"B25001_001E\", \"B19013_001E\", \"B01001A_001E\", \"B01003_001E\", \"B07013_002E\", \"B07013_003E\", \"B08012_001E\", \"B25104_001E\"), year=2018, state=12, county=086, geometry=T) %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |==                                                                    |   4%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\n#filter for Miami/Miami beach tracts\nacs <-\n  rbind(\n    st_centroid(acs)[miamiBound,] %>%\n      st_drop_geometry() %>%\n      left_join(acs) %>%\n      st_sf() %>%\n      mutate(inMiami = \"YES\"),\n    st_centroid(acs)[miamiBound, op = st_disjoint] %>%\n      st_drop_geometry() %>%\n      left_join(acs) %>%\n      st_sf() %>%\n      mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n  dplyr::select(-inMiami)\n#long to wide form\nacs <-\n  acs %>%\n  dplyr::select(-moe, -GEOID) %>%\n  spread(variable, estimate) %>%\n  dplyr::select(-geometry) %>%\n  rename(vacantUnits = B25002_003,\n         totalUnits = B25001_001,\n         medHHInc = B19013_001,\n         white = B01001A_001,\n         population = B01003_001,\n         ownerOcc = B07013_002,\n         renterOcc = B07013_003,\n         timeToWork = B08012_001,\n         monthhousingcost = B25104_001)\nacs[\"119\", \"medHHInc\"] = 33194   #input value from nearby tract in same neighborhod because NA was messing up MAE\nacs %>% na.omit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 122 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 880420.7 ymin: 500177.1 xmax: 945983.6 ymax: 560361.7\nProjected CRS: NAD_1983_StatePlane_Florida_East_FIPS_0901_Feet\nFirst 10 features:\n                                             NAME white population ownerOcc\n1  Census Tract 13.01, Miami-Dade County, Florida  2070       4274     1899\n2  Census Tract 13.02, Miami-Dade County, Florida  3414       4872     2583\n3  Census Tract 14.01, Miami-Dade County, Florida   580       5899      695\n4  Census Tract 14.02, Miami-Dade County, Florida  1292       6839      665\n5  Census Tract 15.01, Miami-Dade County, Florida   319       3924      801\n6  Census Tract 18.02, Miami-Dade County, Florida  1096       4055     1768\n7  Census Tract 19.01, Miami-Dade County, Florida   494       4740      770\n8  Census Tract 19.03, Miami-Dade County, Florida   459       3262     1101\n9  Census Tract 19.04, Miami-Dade County, Florida   670       4198     1306\n10 Census Tract 20.01, Miami-Dade County, Florida   234       4128     1053\n   renterOcc timeToWork medHHInc totalUnits vacantUnits monthhousingcost\n1       2313       2041    23688       2823         287             2536\n2       2264       3154    56651       3038         454             2584\n3       5036       2099    21303       2328         170             2158\n4       6033       2523    23771       2426         122             2304\n5       3076       1055    18092       1447         268             1179\n6       2245       1524    29300       1481         165             1316\n7       3923       1522    25365       2042         243             1799\n8       2046       1098    28875       1507         248             1259\n9       2872       1480    21748       1938         337             1601\n10      2979       1333    17584       1756         162             1594\n                         geometry\n1  MULTIPOLYGON (((922930.8 55...\n2  MULTIPOLYGON (((922969.1 55...\n3  MULTIPOLYGON (((916710.6 55...\n4  MULTIPOLYGON (((920212.7 55...\n5  MULTIPOLYGON (((910983.3 54...\n6  MULTIPOLYGON (((908576.1 54...\n7  MULTIPOLYGON (((913632.1 54...\n8  MULTIPOLYGON (((911114.2 54...\n9  MULTIPOLYGON (((911245 5426...\n10 MULTIPOLYGON (((917262.7 54...\n```\n\n\n:::\n\n```{.r .cell-code}\n#mutate\nacs <-\n  acs %>%\n  mutate(pctVacant = ifelse(totalUnits > 0, vacantUnits / totalUnits, 0),\n         pctWhite = ifelse(population > 0, white / population, 0),\n         totalOcc = ownerOcc + renterOcc,\n         pctRenterOcc = ifelse(totalOcc > 0, renterOcc / totalOcc, 0)) %>%\n  dplyr::select(-totalUnits,-vacantUnits,-totalUnits,-population,-white, -ownerOcc, -renterOcc, -totalOcc)\n\n\n#OSM BBOX (uses the non-projected base)\nxmin = st_bbox(miamiBoundOSM)[[1]]\nymin = st_bbox(miamiBoundOSM)[[2]]\nxmax = st_bbox(miamiBoundOSM)[[3]]  \nymax = st_bbox(miamiBoundOSM)[[4]]\n\n\n\n#FOOD AND BEVERAGE SPOTS\nfoodBev <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/food_bev.geojson\") %>%\n  st_as_sf()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `food_bev' from data source \n  `/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw Data/food_bev.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 556 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 885808 ymin: 506458 xmax: 945707.1 ymax: 555935.3\nProjected CRS: NAD_1983_StatePlane_Florida_East_FIPS_0901_Feet\n```\n\n\n:::\n\n```{.r .cell-code}\n#COASTLINE\nCoastline<-opq(bbox = c(xmin, ymin, xmax, ymax)) %>%\n  add_osm_feature(\"natural\", \"coastline\") %>%\n  osmdata_sf()\n#add to housesOSM and convert to miles, then add to houses\nhousesOSM <-\n  housesOSM %>%  \n  mutate(CoastDist=(geosphere::dist2Line(p=st_coordinates(st_centroid(housesOSM)),\n                                        line=st_coordinates(Coastline$osm_lines)[,1:2])*0.00062137)[,1])\nhouses <-\n  houses %>%\n  mutate(distWater = housesOSM$CoastDist,\n         SPSqFt = ifelse(!is.na(ActualSqFt)&!is.na(SalePrice), SalePrice / ActualSqFt, 0))\n\n\n\n#PARKS\nmuniParks <- st_read(\"https://opendata.arcgis.com/datasets/16fe02a1defa45b28bf14a29fb5f0428_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658') %>%\n  dplyr::select(NAME, ADDRESS, CITY, CLASS, Shape__Area)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Municipal_Park_Boundary' from data source \n  `https://opendata.arcgis.com/datasets/16fe02a1defa45b28bf14a29fb5f0428_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 563 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.49458 ymin: 25.44056 xmax: -80.11871 ymax: 25.97452\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nparks <- \n  # bind_rows(muniParks, countyParks) %>%\n  muniParks %>%\n  filter(CITY == \"Miami\" | CITY == \"Miami Beach\") %>%\n  mutate(counter = 1)\n\n\n\n#SCHOOL DISTRICT\nschoolDist <- st_read(\"https://opendata.arcgis.com/datasets/bc16a5ebcdcd4f3e83b55c5d697a0317_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658') %>%\n  dplyr::select(ID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `SchoolBoardDistrict' from data source \n  `https://opendata.arcgis.com/datasets/bc16a5ebcdcd4f3e83b55c5d697a0317_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 9 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.87361 ymin: 25.13743 xmax: -80.0628 ymax: 25.97949\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#PUBLIC SCHOOL CATCHMENT/ATTENDANCE ZONES\n#elementary\nelementary <- st_read(\"https://opendata.arcgis.com/datasets/19f5d8dcd9714e6fbd9043ac7a50c6f6_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Elementary_School_Attendance_Boundary' from data source \n  `https://opendata.arcgis.com/datasets/19f5d8dcd9714e6fbd9043ac7a50c6f6_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 224 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.67508 ymin: 25.3743 xmax: -80.11807 ymax: 25.97523\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nelementary <- rbind(\n  st_centroid(elementary)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(elementary) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(elementary)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(elementary) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n  dplyr::select(NAME)\n\n#middle\nmiddle <- st_read(\"https://opendata.arcgis.com/datasets/dd2719ff6105463187197165a9c8dd5c_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Middle_School_Attendance_Boundary' from data source \n  `https://opendata.arcgis.com/datasets/dd2719ff6105463187197165a9c8dd5c_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 53 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -80.67463 ymin: 25.37431 xmax: -80.11807 ymax: 25.97515\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nmiddle <- rbind(\n  st_centroid(middle)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(middle) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(middle)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(middle) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n  dplyr::select(NAME)\n\n#high\nhigh <- st_read(\"https://opendata.arcgis.com/datasets/9004dbf5f7f645d493bfb6b875a43dc1_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `High_School_Attendance_Boundary' from data source \n  `https://opendata.arcgis.com/datasets/9004dbf5f7f645d493bfb6b875a43dc1_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 34 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -80.67876 ymin: 25.3743 xmax: -80.11483 ymax: 25.97514\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nhigh <- rbind(\n  st_centroid(high)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(high) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(high)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(high) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n  dplyr::select(NAME)\n\n\n\n#PUBLIC TRANSPORTATION\n#bus\nbus <- st_read(\"https://opendata.arcgis.com/datasets/021adadcf6854f59852ff4652ad90c11_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\")  %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Bus_Stop' from data source \n  `https://opendata.arcgis.com/datasets/021adadcf6854f59852ff4652ad90c11_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 7425 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -81.07573 ymin: 24.71614 xmax: -80.12018 ymax: 26.1231\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nbus <- rbind(\n  bus[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(bus) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  bus[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(bus) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n\n#metro mover\nmetromover <- st_read(\"https://opendata.arcgis.com/datasets/aec76104165c4e879b9b0203fa436dab_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `MetroMoverStations' from data source \n  `https://opendata.arcgis.com/datasets/aec76104165c4e879b9b0203fa436dab_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 21 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.1961 ymin: 25.76039 xmax: -80.18733 ymax: 25.78946\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nmetromover <- rbind(\n  metromover[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(metromover) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  metromover[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(metromover) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n\n#metro rail\nmetrorail <- st_read(\"https://opendata.arcgis.com/datasets/ee3e2c45427e4c85b751d8ad57dd7b16_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `MetroRailStations' from data source \n  `https://opendata.arcgis.com/datasets/ee3e2c45427e4c85b751d8ad57dd7b16_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 23 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.32375 ymin: 25.685 xmax: -80.19547 ymax: 25.8458\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nmetrorail <- rbind(\n  metrorail[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(metrorail) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  metrorail[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(metrorail) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n\n\n\n#CULTURE SPOTS\nculture <- st_read(\"https://opendata.arcgis.com/datasets/70c48f0eb067448c8a787cfa1c1c3bb9_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `CultureVenue' from data source \n  `https://opendata.arcgis.com/datasets/70c48f0eb067448c8a787cfa1c1c3bb9_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 70 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.47835 ymin: 25.46526 xmax: -80.12108 ymax: 25.9584\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nculture <- rbind(\n  culture[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(culture) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  culture[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(culture) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n\n\n\n#COMMERCIAL PROPERTIES\n#read, project\ncommercial <- st_read(\"https://opendata.arcgis.com/datasets/fb8303c577c24ea386a91be7329842be_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `CommercialProperty' from data source \n  `https://opendata.arcgis.com/datasets/fb8303c577c24ea386a91be7329842be_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 88885 features and 20 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.63512 ymin: 25.30789 xmax: -80.12 ymax: 25.97436\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#filter\ncommercial <- rbind(\n  commercial[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(commercial) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  commercial[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(commercial) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n\n\n\n#FLOOD RISK ZONES\nfloodRisk <- st_read(\"https://opendata.arcgis.com/datasets/ef3bdd041b2e424695eb4dfe965966c4_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `FEMA_Flood_Zone' from data source \n  `https://opendata.arcgis.com/datasets/ef3bdd041b2e424695eb4dfe965966c4_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 3560 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -80.87358 ymin: 25.13742 xmax: -80.09375 ymax: 25.97944\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#filter\n floodRisk <-\n   rbind(\n  st_centroid(floodRisk)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(floodRisk) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(floodRisk)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(floodRisk) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n   dplyr::select(-inMiami, -ELEV) %>%\n   dplyr::rename(FloodZone = FZONE, FloodHazard = ZONESUBTY)\n\n\n floodInsure <- st_read(\"https://opendata.arcgis.com/datasets/f589473ddada46e78d437aaf09205b04_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `FEMAPanel' from data source \n  `https://opendata.arcgis.com/datasets/f589473ddada46e78d437aaf09205b04_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 251 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -80.875 ymin: 25.125 xmax: -80.09375 ymax: 26\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n floodInsure <-\n   rbind(\n  st_centroid(floodInsure)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(floodInsure) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(floodInsure)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(floodInsure) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\") %>%\n   mutate(floodInsureType = PANELID)\n\n\n\n#CONTAMINATED SITES\ncontaminated <- st_read(\"https://opendata.arcgis.com/datasets/43750f842b1e451aa0347a2ca34a61d7_0.geojson\") %>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Contaminated_Site' from data source \n  `https://opendata.arcgis.com/datasets/43750f842b1e451aa0347a2ca34a61d7_0.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 3320 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.62586 ymin: 25.413 xmax: -80.1198 ymax: 25.97371\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncontaminated <-\n   rbind(\n  st_centroid(contaminated)[miamiBound,] %>%\n    st_drop_geometry() %>%\n    left_join(contaminated) %>%\n    st_sf() %>%\n    mutate(inMiami = \"YES\"),\n  st_centroid(contaminated)[miamiBound, op = st_disjoint] %>%\n    st_drop_geometry() %>%\n    left_join(contaminated) %>%\n    st_sf() %>%\n    mutate(inMiami = \"NO\")) %>%\n  filter(inMiami == \"YES\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#CONTAMINATION BUFFER\n\n contamBuffer <- contaminated %>%\n   st_buffer(800) %>%\n   st_union() %>%\n   st_as_sf() %>%\n   mutate(contam = 1)\n houses$contaminated <- houses %>%\n   st_join(contamBuffer) %>%\n   mutate(contam = ifelse(is.na(contam), 0, 1)) %>%\n   pull(contam)\n\n\n\n#NEAREST NEIGHBOR (some are used for testing, to determine feature buffer distances)\n st_c <- st_coordinates\n houses <-\n   houses %>%\n   mutate(\n     #commercial properties NN\n     commNN1 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(commercial)), 1),\n     commNN5 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(commercial)), 5),\n     #metro mover stations\n     metroMNN1 = nn_function(st_c(st_centroid(houses)), st_c(metromover), 1),\n     metroMNN5 = nn_function(st_c(st_centroid(houses)), st_c(metromover), 5),\n     #metro rail stations\n     metroRNN1 = nn_function(st_c(st_centroid(houses)), st_c(metrorail), 1),\n     metroRNN5 = nn_function(st_c(st_centroid(houses)), st_c(metrorail), 5),\n     #food/drinks\n     foodBevNN1 = nn_function(st_c(st_centroid(houses)), st_c(foodBev), 1),\n     foodBevNN5 = nn_function(st_c(st_centroid(houses)), st_c(foodBev), 5)\n     ) \n\n\n#COMMERCIAL BUFFER\n commercial <- commercial %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count properties within each buffer\nhouses$commercialProperties <-\n   st_buffer(houses, 846) %>%\n   aggregate(commercial, ., sum) %>%\n   st_drop_geometry() %>%\n  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n#FOOD AND BEV BUFFER\n foodBev <- foodBev %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count parks within each buffer\nhouses$foodEstablishments <-\n   st_buffer(houses, 2774) %>%\n   aggregate(foodBev, ., sum) %>%\n   st_drop_geometry() %>%\n    mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n#CULTURE BUFFER\n culture <- culture %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count culture within each buffer\nhouses$cultureSpots <-\n   st_buffer(houses, 774) %>%\n   aggregate(culture, ., sum) %>%\n   st_drop_geometry() %>%\n   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n\n#METRORAIL BUFFER\n metrorail <- metrorail %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count stops within each buffer\nhouses$metrorailStops <-\n   st_buffer(houses, 12076.7) %>%\n   aggregate(metrorail, ., sum) %>%\n   st_drop_geometry() %>%\n  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n#METROMOVER BUFFER\n metromover <- metromover %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count metroM stops within each buffer\nhouses$metromoverStops <-\n   st_buffer(houses, 18845) %>%\n   aggregate(metromover, ., sum) %>%\n   st_drop_geometry() %>%\n   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n#BUS BUFFER\n bus <- bus %>%\n   mutate(counter = 1) %>%\n   dplyr::select(counter)\n #count bus within each buffer\nhouses$busStops <-\n   st_buffer(houses, 775) %>%\n   aggregate(bus, ., sum) %>%\n   st_drop_geometry() %>%\n  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n\n\n\n #PARKS BUFFER + AREA CALCULATION (using 1600ft buffer distance because the mean NN1 = 1600)\n #get centroids\n parkCentroids <- parks %>%\n   st_centroid(parks) %>%    #get centroids of park layer\n  dplyr::select(counter)\n #count parks within each buffer\nhouses$parkCount <-\n   st_buffer(houses, 1600) %>%\n   aggregate(parkCentroids, ., sum) %>%\n   st_drop_geometry() %>%\n   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%\n   pull(counter)\n#make buffer for each house\nparkBuffer <- st_buffer(houses, 1600) %>%\n  dplyr::select(Property.Address) %>%\n  st_as_sf()\n#calculate area of park space in each buffer\nbufferedParks <- st_intersection(parkBuffer, parks) %>%\n  group_by(Property.Address) %>%\n  summarise() %>%\n  mutate(parkArea = units::drop_units(st_area(.))) %>%\n  st_drop_geometry()\n#add park area back to houses file\nhouses <-\n  left_join(houses, bufferedParks)\n\n\n\n#SCHOOL CATCHMENT CATEGORIES\n houses <-\n   st_join(houses, elementary) %>%\n   rename(elemCatch = 'NAME')\n\n  houses <-\n   st_join(houses, middle) %>%\n   rename(middleCatch = 'NAME')\n\n   houses <-\n   st_join(houses, high) %>%\n   rename(highCatch = 'NAME')\n\n\n\n #SCHOOL DISTRICT CATEGORIES\n houses <-\n   st_join(houses, schoolDist) %>%\n   rename(schoolDist = ID)\n\n\n #FLOOD INSURANCE CATEGORIES\nfloodInsure <- floodInsure %>%\n  dplyr::select(floodInsureType)\nhouses <- houses %>%\n  st_join(., floodInsure) %>%\n  mutate(floodInsureType = ifelse(is.na(floodInsureType), \"other\", floodInsureType))\n\n\n\n#ADD ACS DATA\nhouses <-\n  st_join(houses, acs)\n\n\n\n\n #HOUSE AGE\nhouses <-\n   houses %>%\n   mutate(age = ifelse(is.na(YearBuilt), 0, (2020 - YearBuilt)))\n\n\n\n #MAKE CATEGORICAL VARIABLES\n houses <-\n  houses %>%\n  mutate(Bed.cat = case_when(\n                  Bed >= 0 & Bed < 3  ~ \"Up to 2 Beds\",\n                  Bed >= 3 & Bed < 4  ~ \"3 Beds\",\n                  Bed >= 4                    ~ \"4+ Beds\"))\n\n\n houses <-\n  houses %>%\n  mutate(Bath.cat = case_when(\n                  Bath < 2  ~ \"Up to 1 Bathroom\",\n                  Bath == 2  ~ \"2 Bathrooms\",\n                  Bath >= 3                    ~ \"3+ Bathrooms\"))\n\n\n houses <-\n  houses %>%\n  mutate(Stories.cat = case_when(\n                  Stories < 2  ~ \"Up to 1 Stories\",\n                  Stories == 2  ~ \"2 Stories\",\n                  Stories >= 3                    ~ \"3+ Stories\"))\n\n\n\n houses <-\n  houses %>%\n  mutate(distWater.cat = case_when(\n                  distWater < 0.25  ~ \"Less than 1/4 Mile\",\n                  distWater >= 0.25   ~ \"More than 1/4 Mile\"))\n\n\n houses <-\n  houses %>%\n  mutate(parkArea.cat = case_when(\n                  parkArea < 57000  ~ \"Less than 57,000 SqFt\",\n                  parkArea >= 57000 & parkArea < 320000  ~ \"57,000 - 320,000 SqFt\",\n                  parkArea >= 320000              ~ \"More than 320,000 SqFt\"))\n\n\n\n #OTHER HOUSE FEATURES\nhouses <- houses %>%\n  mutate(Pool = ifelse(str_detect(XF1, \"Pool\") | str_detect(XF2, \"Pool\") | str_detect(XF3, \"Pool\") | str_detect(XF1, \"Whirlpool\") | str_detect(XF2, \"Whirlpool\") | str_detect(XF3, \"Whirlpool\") | str_detect(XF1, \"Jacuzzi\") | str_detect(XF2, \"Jacuzzi\") | str_detect(XF3, \"Jacuzzi\"), \"Pool\", \"No Pool\"),\n         Patio = ifelse(str_detect(XF1, \"Patio\") | str_detect(XF2, \"Patio\") | str_detect(XF3, \"Patio\"), \"Patio\", \"No Patio\"),\n         Fence = ifelse(str_detect(XF1, \"Fence\") | str_detect(XF2, \"Fence\") | str_detect(XF3, \"Fence\"), \"Fence\", \"No Fence\"),\n         Gazebo = ifelse(str_detect(XF1, \"Gazebo\") | str_detect(XF2, \"Gazebo\") | str_detect(XF3, \"Gazebo\"), \"Gazebo\", \"No Gazebo\"),\n         Carport = ifelse(str_detect(XF1, \"Carport\") | str_detect(XF2, \"Carport\") | str_detect(XF3, \"Carport\"), \"Carport\", \"No Carport\"),\n         Wall = ifelse(str_detect(XF1, \"Wall\") | str_detect(XF2, \"Wall\") | str_detect(XF3, \"Wall\"), \"Wall\", \"No Wall\"),\n         Dock = ifelse(str_detect(XF1, \"Dock\") | str_detect(XF2, \"Dock\") | str_detect(XF3, \"Dock\"), \"Dock\", \"No Dock\"),\n         )\n\n#FIX NA VALUES\n#zip\n houses <-\n  houses %>%\n  mutate(Mailing.Zip = as.numeric(Mailing.Zip),\n         Mailing.Zip = ifelse(is.na(Mailing.Zip), 0, Mailing.Zip))\n\n#School dist\n houses <-\n   houses %>%\n  mutate(elemCatch = ifelse(is.na(elemCatch), \"other\", elemCatch),\n         middleCatch = ifelse(is.na(middleCatch), \"other\", middleCatch),\n         highCatch = ifelse(is.na(highCatch), \"other\", highCatch),\n         )\n\n\n\n#park\n houses <- houses %>%\n     mutate(parkArea = ifelse(is.na(parkArea), 0, parkArea))\n\n #acs - here I found the location of NA values and gave these houses the ACS values of houses nearby/in same neighborhood\nhouses[\"3487\", \"NAME\"] = houses[\"1099\", \"NAME\"]\nhouses[\"3487\",\"timeToWork\"] =  houses[\"1099\",\"timeToWork\"]\nhouses[\"3487\", \"medHHInc\"] = houses[\"1099\", \"medHHInc\"]\nhouses[\"3487\", \"monthhousingcost\"] = houses[\"1099\", \"monthhousingcost\"]\nhouses[\"3487\", \"pctVacant\"] = houses[\"1099\", \"pctVacant\"]\nhouses[\"3487\", \"pctWhite\"] = houses[\"1099\", \"pctWhite\"]\nhouses[\"3487\", \"pctRenterOcc\"] = houses[\"1099\", \"pctRenterOcc\"]\n\n\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"NAME\"] = houses[\"3458\", \"NAME\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"timeToWork\"] = houses[\"3458\", \"timeToWork\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"medHHInc\"] = houses[\"3458\", \"medHHInc\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"monthhousingcost\"] = houses[\"3458\", \"monthhousingcost\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"pctVacant\"] = houses[\"3458\", \"pctVacant\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"pctWhite\"] = houses[\"3458\", \"pctWhite\"]\nhouses[c(\"579\",\"580\",\"581\",\"1016\",\"1372\",\"1557\",\"1853\",\"2140\",\"2557\",\"2563\",\"2571\",\"2603\",\"2786\",\"2981\",\"3050\",\"3361\"), \"pctRenterOcc\"] = houses[\"3458\", \"pctRenterOcc\"]\n\nhouses[\"441\", c(\"NAME\",\"timeToWork\",\"medHHInc\",\"monthhousingcost\",\"pctVacant\",\"pctWhite\",\"pctRenterOcc\")] = houses[\"2090\", c(\"NAME\",\"timeToWork\",\"medHHInc\",\"monthhousingcost\",\"pctVacant\",\"pctWhite\",\"pctRenterOcc\")]\n\nhouses %>%\n  dplyr::select(-Property.Zip)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#table of summary statistics with variable descriptions, sorted by category\n\nhousesSub <- houses %>%\n  dplyr::select(\"AdjustedSqFt\", \"LotSize\", \"Bed\", \"Bath\", \"Stories\", \"commercialProperties\", \"age\", \"distWater\", \"foodEstablishments\", \"cultureSpots\", \"busStops\", \"parkArea\", \"timeToWork\",\"monthhousingcost\",\"pctVacant\")\n\nhousesSub <- st_drop_geometry(housesSub)\nstargazer(as.data.frame(housesSub), type=\"text\", digits=1, title=\"Table 1: Descriptive Statistics for Miami Houses\", out = \"Miami Data.txt\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTable 1: Descriptive Statistics for Miami Houses\n==================================================================\nStatistic              N     Mean    St. Dev.    Min       Max    \n------------------------------------------------------------------\nAdjustedSqFt         3,503  2,082.2   1,426.0    331     18,006   \nLotSize              3,503  7,657.8   4,401.4  1,250.0  80,664.0  \nBed                  3,503    3.0       1.1       0        13     \nBath                 3,503    2.1       1.3       0        12     \nStories              3,503    1.2       0.4       0         4     \ncommercialProperties 3,503   15.6      26.1       0        203    \nage                  3,503   69.2      22.5       1        115    \ndistWater            3,503    1.1       1.3     0.000      5.4    \nfoodEstablishments   3,503    3.7       8.4       0        119    \ncultureSpots         3,503   0.01       0.1       0         1     \nbusStops             3,503    2.0       2.2       0        11     \nparkArea             3,503 310,403.1 655,411.8   0.0   4,625,338.0\ntimeToWork           3,503  2,347.2   1,200.6    476      5,962   \nmonthhousingcost     3,503  1,888.9    807.6     390      5,078   \npctVacant            3,503    0.2       0.1      0.0       0.5    \n------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\nFirst, we use a correlation matrix (Figure 1) to get an idea of different variables' correlations with sale price. Below is a list of positive and negative correlations:\n\nPositive:  \n- AdjustedSqFt  \n- Bath  \n- Bed  \n- Stories  \n- Food establishments (Slight)  \n- Park Area  \n- Median household income  \n\nNegative:  \n- Time to work  \n- Monthly housing cost  \n- Age  \n- Percent renter occupancy \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrPlotVars <- houses %>%\n  dplyr::select(-saleDate, -saleType, -saleYear, -Bldg, -Land, -Assessed, -WVDB, -HEX, -GPAR, -County.2nd.HEX, -County.Senior, -County.LongTermSenior, -County.Other.Exempt, -County.Taxable, -City.2nd.HEX, -City.Senior, -City.LongTermSenior, -City.Other.Exempt, -City.Taxable, -MillCode, -Owner1, -Owner2, -Mailing.State, -Mailing.Country, -Legal1, -Legal2, -Legal3, -Legal4, -Legal5, -Legal6, -YearBuilt, -EffectiveYearBuilt, -toPredict)\n\nnumericVars <-\n  select_if(st_drop_geometry(corrPlotVars), is.numeric) %>% na.omit()\n\nggcorrplot(\n  round(cor(numericVars), 1),\n  p.mat = cor_pmat(numericVars),\n  colors = c(\"#25CB10\", \"white\", \"#FA7800\"),\n  type=\"lower\",\n  insig = \"blank\") +  \n    labs(title = \"Figure 1: Sale Price Correlation with Numeric Variables\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 1- Correlation Matrix-1.png){width=960}\n:::\n:::\n\n\n\nThree variables that we will explore further are distWater, parkArea, pctVacant, and busStops. We expect that higher distWater and pctVacant values correlate with low sale prices, and parkArea and busStops make nearby houses more expensive and cost more.\n\nAs expected, proximity to the shoreline (low distWater) is desirable, and correlates with higher sale price. Based on Figure 2.1, however, this trend is strongest when distWater < 1. This suggests that we need to feature engineer distWater to account for greater correlation at shorter distances. The amount of park area near a house is positively correlated with sale price, although not as strongly as expected (Figure 2.2).  \n\t\nSurprisingly, the share of a census tract that is vacant has a positive correlation with sale price (Figure 2.3). This is unexpected because typically, vacant houses correlate with neighborhood disorder and unattractiveness. However, it is possible that these vacancies are the result of new construction and therefore do not make the area less attractive.\n\nBus stops also defy our understanding of cities: according to TOD theory, homes near transportation should be more attractive. However, as Figure 2.4 shows, the number of nearby bus stops correlates negatively with sale price. This may be because lower-income households tend to rely more on public transit.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhousesKnown <- houses %>%    \n  filter(.,toPredict == 0)\nhousesUnknown <- houses %>%\n  filter(.,toPredict ==1)\n\n#1: distWater\nggplot(data = housesKnown, aes(x = distWater, y = SalePrice)) +\n  geom_point(size=2, shape=20)  +\n  labs(title = \"Figure 2.1: Distance to Shoreline and Sale Price\", subtitle = \"Miami and Miami Beach, FL\") +\n  geom_smooth(method = \"lm\", se=F, colour = \"green\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 2.1-2.4- 4 SCATTERPLOT home price correlation-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#2: parkArea\nggplot(data = housesKnown, aes(x = parkArea, y = SalePrice)) +\n  geom_point(size=2, shape=20) +\n  labs(title = \"Figure 2.2: Nearby Park Space and Sale Price\", subtitle = \"Miami and Miami Beach, FL\") +\n  geom_smooth(method = \"lm\", se=F, colour = \"green\") +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 2.1-2.4- 4 SCATTERPLOT home price correlation-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#3: vacant\nggplot(data = housesKnown, aes(x = pctVacant, y = SalePrice)) +\n  geom_point(size=2, shape=20) +\n labs(title = \"Figure 2.3: Share of Vacant Properties and Sale Price\", subtitle = \"Miami and Miami Beach, FL\") +\n  geom_smooth(method = \"lm\", se=F, colour = \"green\") +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 2.1-2.4- 4 SCATTERPLOT home price correlation-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#4: bus stops\nggplot(data = housesKnown, aes(x = busStops, y = SalePrice)) +\n  geom_point(size=2, shape=20) +\n labs(title = \"Figure 2.4: Bus Stops and Sale Price\", subtitle = \"Miami and Miami Beach, FL\") +\n  geom_smooth(method = \"lm\", se=F, colour = \"green\") +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 2.1-2.4- 4 SCATTERPLOT home price correlation-4.png){width=672}\n:::\n:::\n\n\n\nWe further examine relationships between variables, sale prices, and space in a series of maps. Figure 3 shows the distribution of observed sale prices. Prices are highest in Miami Beach and the shoreline of Miami. It gets progressively lower until it reaches its lowest cluster in the North.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#map of your dependent variable (sale price)\n  #water is just for mapping visuals\nwater <- st_read(\"https://opendata.arcgis.com/datasets/bf9de3192c9c4e458d1453f6d4c88d6c_0.geojson\") %>%\n st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658') %>%\n  st_union() %>%\n  st_intersection(.,miamiBound)\n\nggplot() +\n  geom_sf(data = acs, fill = \"gray80\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = housesKnown, aes(colour = q5(SalePrice))) +\n  scale_colour_manual(values = paletteMap) +\n  labs(title = \"Figure 3: Home Sale Price\", subtitle = \"Miami and Miami Beach, FL\") +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 3- MAP Sale Price-1.png){width=768}\n:::\n:::\n\n\n\n\n\nNext, we map distWater, AdjustedSqFt, MedHHInc, parkArea, and foodEstablishments.\n\nIt can be expected that distance to water is negatively correlated to sale price in a city known for its beaches. Figure 4.1 shows that distance to the shoreline closely matches sale price. \n\nHowever, it's possible that sale price appears to be strongly correlated with distance to water because of other factors. Downtown Miami is located near the beach, and the heightened development around the beaches and downtown may give the area other attractive features.\n\nTwo of these features are green space and dining venues. Figure 4.2 shows that houses in Miami Beach have the most green space nearby. Interestingly, only some of the high sale price houses have high park area, mostly in Miami Beach. This may be due to crime incidents in park areas. In Figure 4.3, we see similar patterns, with the highest values in the houses in Miami Beach and the north part of Miami's shoreline. This suggests that distance to the shoreline is only part of the story.\n\nOutside of amenities, we expect that sale price correlates with median household income of census tracts and the adjusted square footage of houses. In Figures 4.4 and 4.5, we see this confirmed: much like sale price, the highest values for income and square footage are along the shoreline. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#1: distWater\nggplot() +\ngeom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = houses, aes(colour = q5(distWater))) +\n  labs(title = \"Figure 4.1: Distance to Shore\", subtitle = \"Miami and Miami Beach, FL\") +\n  scale_colour_manual(values = palette5) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 4.1-4.5- MAP 3 Independent Variables-1.png){width=768}\n:::\n\n```{.r .cell-code}\n#2: parkArea\nggplot() +\n  geom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = housesKnown, aes(colour = q5(parkArea))) +\n  scale_colour_manual(values = palette5) +\n  labs(title = \"Figure 4.2: Nearby Park Area\", subtitle = \"Miami, FL\") +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 4.1-4.5- MAP 3 Independent Variables-2.png){width=768}\n:::\n\n```{.r .cell-code}\n#3: Food and bev\nggplot() +\n  geom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = housesKnown, aes(colour = q5(foodEstablishments))) +\n  scale_colour_manual(values = palette5) +\n  labs(title = \"Figure 4.3: Number of Nearby Food/Bev Places\", subtitle = \"Miami, FL\") +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 4.1-4.5- MAP 3 Independent Variables-3.png){width=768}\n:::\n\n```{.r .cell-code}\n#4: AdjustedSqFt\n  ggplot() +\ngeom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = houses, aes(colour = q5(AdjustedSqFt))) +\n  labs(title = \"Figure 4.4: Adjusted Square Feet\", subtitle = \"Miami and Miami Beach, FL\") +\n  scale_colour_manual(values = palette5) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 4.1-4.5- MAP 3 Independent Variables-4.png){width=768}\n:::\n\n```{.r .cell-code}\n#5: MedHHInc\n  ggplot() +\ngeom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n  geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = houses, aes(colour = q5(medHHInc))) +\n  labs(title = \"Figure 4.5: Tract Median Household Income\", subtitle = \"Miami and Miami Beach, FL\") +\n  scale_colour_manual(values = palette5) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 4.1-4.5- MAP 3 Independent Variables-5.png){width=768}\n:::\n:::\n\n\n\n## Methods \nNow knowing that attractive amenities, high income households, large houses, and high sale prices cluster around the shoreline area, we can begin to test features to put in our regression model. We ranked the correlation of each feature with sale price, then added them in order until each addition feature no longer increased the model's predictive power for sale price. The regression model that we chose includes house internal features, census tract variables, transportation availability, park area, and flood risk.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n #0.72 R2\n  reg2 <- lm(SalePrice ~ ., data = st_drop_geometry(housesKnown) %>%\n             dplyr::select(SalePrice, ActualSqFt, LotSize, Zoning, Stories.cat, Bath.cat, Pool, medHHInc, Dock, Bed.cat, middleCatch, age, pctVacant, pctRenterOcc, monthhousingcost, Patio, foodEstablishments, timeToWork, metromoverStops, metrorailStops, parkArea, floodInsureType))\n```\n:::\n\n\n\nNext, to test this model, we used houses with observed sale prices to create a training set for training our model, and a test set for testing it. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#read FL neighborhoods\n#nhoods_fl <- aoi_boundary_HARV <- st_read(\"E:/Upenn/CPLN508/miami/zillow_nghbrhd_feb17/zillow_nghbrhd_feb17.shp\")\nnhoods_fl <- aoi_boundary_HARV <- st_read(\"/Users/annaduan/Desktop/GitHub/Miami-Home-Sales-Prediction/Raw\\ Data/zillow_nghbrhd_feb17/zillow_nghbrhd_feb17.shp\")\nnhoods_mb <- subset(nhoods_fl, CITY == \"MIAMI BEACH\")%>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\nnhoods_m <- subset(nhoods_fl, CITY == \"MIAMI\")%>%\n  st_as_sf(coords = c(\"LON\", \"LAT\"), crs = 4326, agr = \"constant\") %>%\n  st_transform('ESRI:102658')\n\n#Join neighborhoods\nnhoods <- rbind(nhoods_mb, nhoods_m)\nnhoods <- nhoods %>%\n  dplyr::select(NAME) %>%\n  rename(neighborhood = NAME)\nhousesKnown <- housesKnown %>% st_join(., nhoods, join = st_within)\nhouses <- houses %>% st_join(., nhoods, join = st_within)\nhousesUnknown <- housesUnknown %>% st_join(., nhoods, join = st_within)\n\n#Separate test/train sets\n\ninTrain <- createDataPartition(\n              y = paste(housesKnown$Zoning, housesKnown$floodInsureType, housesKnown$neighborhood),\n              p = .60, list = FALSE)\nmiami.training <- housesKnown[inTrain,]\nmiami.test <- housesKnown[-inTrain,]  \n\n\n#Training regression \nreg.training <- \n  lm(SalePrice ~ ., data = st_drop_geometry(miami.training) %>% \n                             dplyr::select(SalePrice, ActualSqFt, LotSize, Zoning, Stories.cat, Bath.cat, Pool, medHHInc, Dock, Bed.cat, middleCatch, age, pctVacant, pctRenterOcc, monthhousingcost, Patio, foodEstablishments, timeToWork, metromoverStops, metrorailStops, parkArea, floodInsureType))\n```\n:::\n\n\n\n## Results\nThe results of the regression model on the training set are presented in Table 2. Overall, the R-squared value of 0.9 means our variables explain most of the variation in sale price. The low p values also indicate a high level of confidence.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#polished table of  (training set) lm summary results (coefficients, R2 etc)\nstargazer(reg.training, type=\"text\", digits=1, title=\"Table 2: LM of Training Data\", out = \"Training LM.txt\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTable 2: LM of Training Data\n=====================================================================\n                                              Dependent variable:    \n                                          ---------------------------\n                                                   SalePrice         \n---------------------------------------------------------------------\nActualSqFt                                         809.4***          \n                                                    (26.1)           \n                                                                     \nLotSize                                             19.7***          \n                                                     (7.6)           \n                                                                     \nZoning0104 - SINGLE FAM - ANCILIARY UNIT           136,878.5         \n                                                  (83,726.3)         \n                                                                     \nZoning0800 - SGL FAMILY - 1701-1900 SQ          1,657,367.0***       \n                                                  (141,119.3)        \n                                                                     \nZoning2100 - ESTATES - 15000 SQFT LOT           4,892,538.0***       \n                                                  (289,756.0)        \n                                                                     \nZoning2200 - ESTATES - 25000 SQFT LOT           2,521,079.0***       \n                                                  (410,144.8)        \n                                                                     \nZoning2800 - TOWNHOUSE                             138,460.4         \n                                                  (392,886.5)        \n                                                                     \nZoning3900 - MULTI-FAMILY - 38-62 U/A              101,879.0         \n                                                  (156,568.8)        \n                                                                     \nZoning3901 - GENERAL URBAN 36 U/A LIMITED          194,058.4         \n                                                  (191,246.4)        \n                                                                     \nZoning4600 - MULTI-FAMILY - 5 STORY                                  \n                                                  (258,142.1)        \n                                                                     \nZoning4601 - MULTI-FAMILY - 8 STORY                                  \n                                                  (592,303.7)        \n                                                                     \nZoning4801 - RESIDENTIAL-LIMITED RETAI             318,384.7         \n                                                  (414,682.1)        \n                                                                     \nZoning5700 - DUPLEXES - GENERAL                    90,856.1          \n                                                  (74,052.0)         \n                                                                     \nZoning6100 - COMMERCIAL - NEIGHBORHOOD            -121,653.7         \n                                                  (315,773.9)        \n                                                                     \nZoning6101 - CEN-PEDESTRIAN ORIENTATIO             220,467.6         \n                                                  (294,505.3)        \n                                                                     \nZoning6106 - RESIDENTIAL-LIBERAL RETAI           1,058,300.0*        \n                                                  (604,279.2)        \n                                                                     \nZoning6107 - RESIDENTIAL-MEDIUM RETAIL             318,062.9         \n                                                  (252,600.1)        \n                                                                     \nZoning6110 - COMM/RESIDENTIAL-DESIGN D             227,589.7         \n                                                  (436,452.2)        \n                                                                     \nZoning6402 - URBAN CORE 24 STORY/7FLR             1,177,944.0        \n                                                  (831,386.1)        \n                                                                     \nZoning7000 - INDUSTRIAL - GENERAL                  172,657.3         \n                                                  (820,573.0)        \n                                                                     \nZoning7700 - INDUSTRIAL - RESTRICTED               97,792.4          \n                                                  (425,260.8)        \n                                                                     \nStories.cat3+ Stories                           2,373,124.0***       \n                                                  (215,085.2)        \n                                                                     \nStories.catUp to 1 Stories                       265,446.1***        \n                                                  (73,874.1)         \n                                                                     \nBath.cat3+ Bathrooms                             -209,950.7***       \n                                                  (74,734.5)         \n                                                                     \nBath.catUp to 1 Bathroom                         173,317.1***        \n                                                  (61,613.8)         \n                                                                     \nPoolPool                                           -90,404.8         \n                                                  (67,653.6)         \n                                                                     \nmedHHInc                                              0.1            \n                                                     (1.0)           \n                                                                     \nDockNo Dock                                        37,514.2          \n                                                  (127,498.8)        \n                                                                     \nBed.cat4+ Beds                                   -299,437.4***       \n                                                  (69,401.4)         \n                                                                     \nBed.catUp to 2 Beds                                98,743.1*         \n                                                  (58,531.2)         \n                                                                     \nmiddleCatchde Diego, Jose Middle                   42,445.0          \n                                                  (146,653.0)        \n                                                                     \nmiddleCatchJones-Ayers, Georgia Middle             -2,197.8          \n                                                  (136,868.4)        \n                                                                     \nmiddleCatchKinloch Park Middle                     95,087.5          \n                                                  (175,948.6)        \n                                                                     \nmiddleCatchMann, Horace Middle                     20,295.3          \n                                                  (156,232.3)        \n                                                                     \nmiddleCatchNautilus Middle                         314,217.9         \n                                                  (275,758.2)        \n                                                                     \nmiddleCatchother                                   108,823.5         \n                                                  (130,522.3)        \n                                                                     \nmiddleCatchPonce de Leon Middle                   306,793.1**        \n                                                  (137,105.9)        \n                                                                     \nmiddleCatchShenandoah Middle                       154,833.0         \n                                                  (116,517.5)        \n                                                                     \nage                                               -3,650.5***        \n                                                   (1,124.7)         \n                                                                     \npctVacant                                         -767,944.7*        \n                                                  (411,180.3)        \n                                                                     \npctRenterOcc                                       82,585.3          \n                                                  (220,471.9)        \n                                                                     \nmonthhousingcost                                     -58.7           \n                                                    (83.4)           \n                                                                     \nPatioPatio                                       -106,396.3**        \n                                                  (45,128.1)         \n                                                                     \nfoodEstablishments                                  2,997.5          \n                                                   (3,157.7)         \n                                                                     \ntimeToWork                                            8.0            \n                                                    (54.6)           \n                                                                     \nmetromoverStops                                   18,025.9***        \n                                                   (6,373.4)         \n                                                                     \nmetrorailStops                                     -34,047.6         \n                                                  (24,750.6)         \n                                                                     \nparkArea                                            -0.1***          \n                                                    (0.05)           \n                                                                     \nfloodInsureType0294                                -42,071.9         \n                                                  (119,714.7)        \n                                                                     \nfloodInsureType0304                                -1,574.5          \n                                                  (202,154.5)        \n                                                                     \nfloodInsureType0307                                -70,322.9         \n                                                  (292,498.3)        \n                                                                     \nfloodInsureType0308                                180,146.8         \n                                                  (236,245.4)        \n                                                                     \nfloodInsureType0309                               532,531.1*         \n                                                  (291,610.9)        \n                                                                     \nfloodInsureType0311                               -199,571.5         \n                                                  (220,728.7)        \n                                                                     \nfloodInsureType0312                                -72,665.9         \n                                                  (246,097.0)        \n                                                                     \nfloodInsureType0313                               -209,305.7         \n                                                  (212,114.1)        \n                                                                     \nfloodInsureType0314                               -147,863.1         \n                                                  (236,555.7)        \n                                                                     \nfloodInsureType0316                             1,741,574.0***       \n                                                  (336,744.8)        \n                                                                     \nfloodInsureType0317                                413,588.0         \n                                                  (298,447.8)        \n                                                                     \nfloodInsureType0318                             2,042,777.0***       \n                                                  (524,739.0)        \n                                                                     \nfloodInsureType0319                             13,474,982.0***      \n                                                  (959,114.5)        \n                                                                     \nfloodInsureType0476                               -122,794.8         \n                                                  (197,385.2)        \n                                                                     \nfloodInsureType0477                               -410,291.2         \n                                                  (296,743.5)        \n                                                                     \nfloodInsureTypeother                               33,964.0          \n                                                  (179,709.2)        \n                                                                     \nConstant                                        -1,205,152.0***      \n                                                  (295,315.9)        \n                                                                     \n---------------------------------------------------------------------\nObservations                                         1,651           \nR2                                                    0.9            \nAdjusted R2                                           0.9            \nResidual Std. Error                          807,791.1 (df = 1586)   \nF Statistic                                177.2*** (df = 64; 1586)  \n=====================================================================\nNote:                                     *p<0.1; **p<0.05; ***p<0.01\n```\n\n\n:::\n:::\n\n\n\nNext, we test the model on our test set to see its effectiveness on new data. Overall, it is relatively accurate: the average percentage error is 7.1%. However, the mean absolute error is $ 351,281, which is concerning as the average price in the test set is $ 689,606. This may be because our model is less accurate for expensive houses, as the absolute errors for them is higher at a given percentage error. Indeed, in Figure 5.1 and 5.2, absolute error is higher for homes with high observed prices, but  percent error is consistently low, at less than 10%.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Test regression on miami.test\nmiami.test <-\n  miami.test %>%\n  mutate(Regression = \"Baseline Regression\",\n         SalePrice.Predict = predict(reg.training, miami.test), #751571.5\n         SalePrice.Error = SalePrice.Predict - SalePrice, #60608.35\n         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), #363363\n         SalePrice.APE = SalePrice.AbsError / SalePrice) %>% #0.05589877  #corrected \n  filter(SalePrice < 5000000) \n\n#Mean error and APE 432255.1   0.3407089   443611.7 0.1643853 467809 -0.0241117\nmean(miami.test$SalePrice.AbsError, na.rm = T)#[1] 351280.6\nmean(miami.test$SalePrice.APE, na.rm = T)#[1] 0.7101703\nmean(miami.test$SalePrice.Predict, na.rm = T)#[1] 770165.4\n\nggplot(data = miami.test) +\n  geom_point(aes(x = SalePrice, y = SalePrice.AbsError)) +\n  labs(title = \"Figure 5.1: Observed Sale Price and Absolute Error\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 5.1-5.2 Test the regression-1.png){width=768}\n:::\n\n```{.r .cell-code}\nggplot(data = miami.test) +\n  geom_point(aes(x = SalePrice, y = SalePrice.APE)) +\n  labs(title = \"Figure 5.2: Observed Sale Price and Absolute Percent Error\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 5.1-5.2 Test the regression-2.png){width=768}\n:::\n:::\n\n\n\n### Is our model generalizable?\nIn addition to accuracy, generalizability is important for our model to be effective. To do this, we run a K-folds test to test the model on different segments of our test set.\n\nWe see in Table 3 that Fold75, one of the 100 partitioned segments of our test data, has an adjusted R-squared of 0.78 and a mean average error of $350,348.9. While the R^2 is high, the error is more than half of the average predicted price across all folds. These results are similar to the results for our training, which suggests strong generalizability across groups.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#K Folds test\nfitControl <- trainControl(method = \"cv\", number = 100)\nset.seed(825)\n\nreg.cv <- \n  train(SalePrice ~ ., data = st_drop_geometry(housesKnown) %>% \n                                dplyr::select(SalePrice, ActualSqFt, LotSize, Zoning, Stories.cat, Bath.cat, Pool, medHHInc, Dock, Bed.cat, middleCatch, age, pctVacant, pctRenterOcc, monthhousingcost, Patio, foodEstablishments, timeToWork, metromoverStops, metrorailStops, parkArea, floodInsureType), \n     method = \"lm\", trControl = fitControl, na.action = na.pass)\n\n\n#k-fold function online\nkfold.MLR = function(fit,k=10,data=fit$model) {    \n  sum.sqerr = rep(0,k)\n  sum.abserr = rep(0,k)\n  sum.pererr = rep(0,k)\n  y = fit$model[,1]\n  x = fit$model[,-1]\n  n = nrow(data)\n  folds = sample(1:k,nrow(data),replace=T)\n  for (i in 1:k) {\n    fit2 <- lm(formula(fit),data=data[folds!=i,])\n    ypred = predict(fit2,newdata=data[folds==i,])\n    sum.sqerr[i] = sum((y[folds==i]-ypred)^2)\n    sum.abserr[i] = sum(abs(y[folds==i]-ypred))\n    sum.pererr[i] = sum(abs(y[folds==i]-ypred)/y[folds==i])\n  }\n  cv = return(data.frame(RMSEP=sqrt(sum(sum.sqerr)/n),\n                         MAE=sum(sum.abserr)/n,\n             MAPE=(sum(sum.pererr)/n)*100))\n}\n\n#ADDED TODAY\nreg.cv.known <-\n  housesKnown %>%\n  mutate(Regression = \"Baseline Regression\",\n         SalePrice.Predict = predict(reg.cv, housesKnown), #751571.5\n         SalePrice.Error = SalePrice.Predict - SalePrice, #60608.35\n         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), #363363\n         SalePrice.APE = SalePrice.AbsError / SalePrice) %>% #0.05589877  #corrected \n  filter(SalePrice < 5000000) \nfold75 <- reg.cv$control$indexOut$Resample075\n\nreg75 <- reg.cv.known[fold75,c(\"SalePrice\", \"SalePrice.Predict\")]\nreg75.test <-\n  reg75 %>%\n  mutate(SalePrice.Error = SalePrice.Predict - SalePrice, \n         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), \n         SalePrice.APE = SalePrice.AbsError / SalePrice) %>% \n  filter(SalePrice < 5000000) \nreg.cv.rs.min <- reg.cv$resample[75,]\nreg.cv.rs.min$MAPE <- mean(reg75.test$SalePrice.APE)\n\nround_df <- function(x, digits) {\n    # round all numeric variables\n    # x: data frame \n    # digits: number of digits to round\n    numeric_columns <- sapply(x, mode) == 'numeric'\n    x[numeric_columns] <-  round(x[numeric_columns], digits)\n    x\n}\nreg.cv.rs.min <- round_df(reg.cv.rs.min, 2)\n\nlibrary(kableExtra)\n\n\nreg.cv.rs.min <- reg.cv$resample[75,]\n\n\nreg.cv.rs.min %>%                     #AD: knitting stops here\n  gather(Variable, Value) %>%\n  #filter(Variable == \"MAE\" | Variable == \"RMSE\") %>%\n  group_by(Variable) %>%\n    spread(Variable, Value) %>%\n    kable(caption = \"Table 3: Regression Results of One Test Set\") %>%\n   kable_classic(full_width = F, html_font = \"Cambria\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table 3: Regression Results of One Test Set</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> MAE </th>\n   <th style=\"text-align:left;\"> Resample </th>\n   <th style=\"text-align:left;\"> RMSE </th>\n   <th style=\"text-align:left;\"> Rsquared </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 586384.883377361 </td>\n   <td style=\"text-align:left;\"> Fold075 </td>\n   <td style=\"text-align:left;\"> 1115370.98383183 </td>\n   <td style=\"text-align:left;\"> 0.949178161094977 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nFor more context, Figure 6.1 shows that most test sets have errors around $400,000, but that a few outliers skew the average error upward. If the model is generalizable, it should have a clustered distribution of errors. As this is not the case, it appears that the model is not actually predicting consistently across groups of houses.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(reg.cv$resample, aes(x=MAE)) +\n  geom_histogram() +\n  labs(title = \"Figure 6.1: Mean Average Error in Cross Validation Tests\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 6.1- HISTOGRAM results of cross-validation tests-1.png){width=768}\n:::\n:::\n\n\n\n### Do errors cluster spatially?\nOne way to investigate the reason for the model's inconsistency is to look at how it treats houses across space. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(scales)\n\ncoords <- st_coordinates(housesKnown)\nneighborList <- knn2nb(knearneigh(coords, 5)) #5 nearest neighborhoods\n\nspatialWeights <- nb2listw(neighborList, style=\"W\") #not sure what is W here\nhousesKnown$lagPrice <- lag.listw(spatialWeights, housesKnown$SalePrice)\n#plot(housesKnown$SalePrice, housesKnown$lagPrice)\n\ncoords.test <-  st_coordinates(miami.test)\nneighborList.test <- knn2nb(knearneigh(coords.test, 5))\nspatialWeights.test <- nb2listw(neighborList.test, style=\"W\")\n```\n:::\n\n\n\nIn Figure 7.1, we can see that residuals are evenly distributed spatially. This suggests that the low generalizability of the data is not due to spatial processes, but other factors. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#10.1 Map of test set residuals\nlibrary(modelr)\n\nmiami.test$resid <- \n  miami.test %>%\n  as_data_frame() %>%\n  add_residuals(., reg.training, var = \"resid\") %>%\n  dplyr::select(resid, Folio) %>%\n  pull(resid)\n\nggplot() +\ngeom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n    geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = miami.test, aes(colour = q5(resid))) +\n  scale_colour_manual(values = palette5) +\n labs(title = \"Figure 7.1: Test Set Residual Errors\", subtitle = \"Miami and Miami Beach, FL\") +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 7.1- MAP of residuals for test set-1.png){width=768}\n:::\n:::\n\n\n\nTo see more clearly the effect of spatial processes on our errors, we can look at spatial lags, or the clustering of prices and errors. In Figure 8.1, we can see that neighboring houses' price estimate errors do not increase in the same way with sale price. This again tells us that most of our errors are not spatial in nature.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmiami.test %>%                \n  mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)) %>%  \n  ggplot(aes(lagPriceError, SalePrice)) +\n  geom_point() +\n  stat_smooth(aes(lagPriceError, SalePrice), \n             method = \"lm\", se = FALSE, size = 1, colour=\"#FA7800\")+\n  labs(title = \"Figure 8.1: Spatial Lag of Price Errors\") +\n  theme_minimal() + theme(plot.title = element_text(size = 18, colour = \"black\")) \n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 8.1- Spatial lag-1.png){width=768}\n:::\n:::\n\n\n\nFinally, we can use a Moran's I test to gain further insight into the spatial autocorrelation of our model errors. If our model errors are not influenced by spatial processes, we should see a Moran's I of 0. Our Moran's I value is less than 0.2, which confirms that we have very minimal spatial clustering of errors.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranTest <- moran.mc(miami.test$SalePrice.Error,\n                      spatialWeights.test, nsim = 999)\n\nggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +\n  geom_histogram(binwidth = 0.01) +\n  geom_vline(aes(xintercept = moranTest$statistic), colour = \"#FA7800\",size=1) +\n  scale_x_continuous(limits = c(-1, 1)) +\n  labs(title=\"Figure 9.1: Observed and Permuted Moran's I\",\n       subtitle= \"Observed Moran's I in orange\",\n       x=\"Moran's I\",\n       y=\"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 9.1- Morans I-1.png){width=768}\n:::\n:::\n\n\n\n### Accounting for neighborhood variance\nWe now add neighborhood as a feature in our model to account for the differences in sale price across neighborhoods. Table 4 tells us that when we account for neighborhood effects, we actually slightly increase the absolute error but we decrease the absolute percentage error. This may mean that the neighborhood model works best for lower priced homes, and that it increased the error in expensive ones. It also tells us that our Baseline model already accounted for spatial disparities through our use of open data features.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Make new neighborhood regression\nreg.nhood <- lm(SalePrice ~ ., data = as.data.frame(miami.training) %>% \n                                 dplyr::select(neighborhood, SalePrice, ActualSqFt, LotSize, Zoning, Stories.cat, Bath.cat, Pool, medHHInc, Dock, Bed.cat, middleCatch, age, pctVacant, pctRenterOcc, monthhousingcost, Patio, foodEstablishments, timeToWork, metromoverStops, metrorailStops, parkArea, floodInsureType))\n\n#Outcomes\nmiami.test.nhood <-\n  miami.test %>%\n  mutate(Regression = \"Neighborhood Effects\",\n         SalePrice.Predict = predict(reg.nhood, miami.test), #613237.3\n         SalePrice.Error = SalePrice - SalePrice.Predict, # -108442.4      \n         SalePrice.AbsError = abs(SalePrice - SalePrice.Predict), # 491238.7\n         SalePrice.APE = (abs(SalePrice - SalePrice.Predict)) / SalePrice)%>% #0.7109973\n  filter(SalePrice < 5000000)\n\n#Check accuracy\nbothRegressions <-\n  rbind(\n    dplyr::select(miami.test, starts_with(\"SalePrice\"), Regression, neighborhood) %>%\n      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)),\n    dplyr::select(miami.test.nhood, starts_with(\"SalePrice\"), Regression, neighborhood) %>%\n      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)))   \n\nst_drop_geometry(bothRegressions) %>%\n  gather(Variable, Value, -Regression, -neighborhood) %>%\n  filter(Variable == \"SalePrice.AbsError\" | Variable == \"SalePrice.APE\") %>%\n  group_by(Regression, Variable) %>%\n    summarize(meanValue = mean(Value, na.rm = T)) %>%\n    spread(Variable, meanValue) %>%\n    kable(caption = \"Table 4: Neighborhood Effect on Error\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Table 4: Neighborhood Effect on Error\n\n|Regression           | SalePrice.AbsError| SalePrice.APE|\n|:--------------------|------------------:|-------------:|\n|Baseline Regression  |           366733.8|     0.8821752|\n|Neighborhood Effects |           369974.4|     0.8650228|\n\n\n:::\n:::\n\n\n\nIn Figure 10.1, we can see the effect of neighborhood model on the accuracy of our predictions. As suspected, the neighborhood model fits the data only marginally better. For some of the higher priced homes, however, it appears that adding neighborhood as a feature causes an overestimation of price. This may be due to variations within neighborhoods.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbothRegressions %>%\n  dplyr::select(SalePrice.Predict, SalePrice, Regression) %>%\n    ggplot(aes(SalePrice, SalePrice.Predict)) +\n  geom_point() +\n  stat_smooth(aes(SalePrice, SalePrice),\n             method = \"lm\", se = FALSE, size = 1, colour=\"#FA7800\") +\n  stat_smooth(aes(SalePrice.Predict, SalePrice),\n              method = \"lm\", se = FALSE, size = 1, colour=\"#25CB10\") +\n  facet_wrap(~Regression) +\n  labs(title=\"Figure 10.1: Predicted Sale Price and Observed Price\",\n       subtitle=\"Orange line represents a perfect prediction; Green line represents prediction\") +\n  theme_minimal() + theme(plot.title = element_text(size = 18, colour = \"black\"))\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Fig 10.1-PLOT predicted prices as a function of observed prices-1.png){width=768}\n:::\n:::\n\n\n\nFinally, Figure 11.1 shows the prices that we predicted for the set of 3503 Miami area homes. As we saw with the known home sale prices, our predicted prices are highest close to the shoreline and on Miami Beach. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#876 rows\n#filter by toPredict = 1\nhousesPredictions <-                   \n  houses %>%\n  mutate(prediction = predict(reg.nhood, houses),\n         team_name = 'Panda')\n\npredictions <- housesPredictions[,c(\"Folio\", \"prediction\", \"team_name\", \"toPredict\")] %>%\n  st_drop_geometry() %>%\n  filter(toPredict == 1) %>%\n  dplyr::select(-toPredict)\n\n# write.csv(predictions, \"PANDA.csv\") #\"The column names MUST to be \"prediction\", \"Folio\", and \"team_name\"\" - piazza\n\n#Map values\nggplot() +\n  geom_sf(data = acs, fill = \"gray90\", colour = \"white\") +\n    geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n  geom_sf(data = housesPredictions, aes(colour = q5(prediction))) +\n scale_colour_manual(values = palette5) +\n labs(title = \"Figure 11.1: Predicted Sale Price Values\", subtitle = \"Miami and Miami Beach, FL\") +\n # facet_wrap(~toPredict) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 11.1- map of predicted values-1.png){width=768}\n:::\n:::\n\n\n\nIn Figure 12.1, we can see the spatial distribution of our errors. Overall, it appears that mean average percentage error is lower in Miami Beach, where sale prices are higher. It is highest in the center of Miami, and relatively low on the Miami shoreline. This suggests that our errors were smaller in neighborhoods with higher observed sale prices.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Using the test set predictions, provide a map of mean absolute percentage error (MAPE) by neighborhood\nnames(bothRegressions)[names(bothRegressions) == \"neighborhood\"] <- \"neighborhood\"\nst_drop_geometry(bothRegressions) %>%\n  group_by(Regression, neighborhood) %>%\n  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%\n  ungroup() %>%\n  left_join(nhoods) %>%\n    st_as_sf() %>%\n   ggplot() +\n    geom_sf(data = water, fill = \"light blue\", colour = \"light blue\") +\n      geom_sf(colour = \"gray\", aes(fill = q5(mean.MAPE))) +\n      scale_fill_manual(values = paletteMap) +\n  labs(title = \"Figure 12.1: Mean Average Percentage Error by Neighborhood\") +\n      theme_void()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 12.1- Test set predictions, MAPE by neighborhood-1.png){width=768}\n:::\n:::\n\n\n\nFigure 13.1 confirms this trend. We can see clearly that with one exception, neighborhoods with lower mean prices have higher mean average percentage errors. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscatter_hood <-\n    miami.test.nhood %>%\n    group_by(neighborhood) %>%\n    dplyr::select(neighborhood, SalePrice.APE, SalePrice.Predict)\n\nmean_sca_hd <-\n  scatter_hood %>%\n  group_by(neighborhood) %>%\n  summarise_at(vars(\"SalePrice.APE\", \"SalePrice.Predict\"), mean)\n\nplot(mean_sca_hd$SalePrice.Predict, mean_sca_hd$SalePrice.APE, main=\"Figure 13.1: MAPE by Neighborhood and Mean Price by Neighborhood\", xlab=\"Mean Price by Neighborhood\", ylab=\"MAPE by neighborhood\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/Figure 13.1- Scatterplot of MAPE by neighborhood as a function of mean price by neighborhood-1.png){width=768}\n:::\n\n```{.r .cell-code}\n#https://r-graphics.org/recipe-scatter-labels or we can use the method below:\n\n#scatter_mae_mean <- ggplot(mean_sca_hd, aes(x = SalePrice.Predict, y = SalePrice.APE)) +\n#    geom_point() +\n#  theme_minimal()\n\n#scatter_mae_mean +    #AD: this is cool but we can't really see which dot is which neighborhood\n#  annotate(\"text\", x = 820000, y = -11.7, label = \"UPPER EASTSIDE\") +\n#  annotate(\"text\", x = 330000, y = -6.5, label = \"LITTLE HAITI\")+\n#  annotate(\"text\", x = 1300000.82, y = 6.85325579, label = \"NAUTILUS\")+\n#  annotate(\"text\", x = 631682.30, y = 3.57218432, label = \"BISCAYNE POINT\")+\n#  annotate(\"text\", x = 1557855.78, y = 2.81996319, label = \"LA GORCE\")+\n#  annotate(\"text\", x = 2031665.51, y = 1.95167248, label = \"WYNWOOD - EDGEWATER\")+\n#  annotate(\"text\", x = 890031.19, y = -2.16394539, label = \"OVERTOWN\")\n```\n:::\n\n\n\n### Does this model work equally for different demographic groups?\nThe variation in the MAPE of different neighborhoods suggests our model has limited generalizability. To test this, we look at how well it predicts prices across different racial and income contexts. In Figure 14.1 is the racial and income context of Miami. \n\nTable 5 and 6 confirm that this model applies slightly differently for different demographics. In Majority non-white neighborhoods, MAPE is 45% higher than in majority white neighborhoods. Similarly, MAPE is 41% higher in low income neighborhoods than in high income ones. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#RACE & INCOME\n  #make new layer\nacsRaceIncome <-\n  acs %>%\n  mutate(raceContext= ifelse(pctWhite > .5, \"Majority White\", \"Majority Non-White\"),\n         incomeContext = ifelse(medHHInc > 49256.56, \"High Income\", \"Low Income\"))\n#context\ngrid.arrange(ncol = 2,\n  ggplot() + geom_sf(data = na.omit(acsRaceIncome), aes(fill = raceContext)) +\n    scale_fill_manual(values = c(\"#25CB10\", \"#FA7800\"), name=\"Race Context\") +\n    labs(title = \"Figure 14.1: Race Context of Miami and Miami Beach\") +\n    theme_void() + theme(legend.position=\"bottom\"),\n  ggplot() + geom_sf(data = na.omit(acsRaceIncome), aes(fill = incomeContext)) +\n    scale_fill_manual(values = c(\"#25CB10\", \"#FA7800\"), name=\"Income Context\") +\n    labs(title = \"Income Context of Miami and Miami Beach\") +\n    theme_void() + theme(legend.position=\"bottom\"))\n```\n\n::: {.cell-output-display}\n![](miami_hedonic_model_files/figure-html/14- race and income-1.png){width=768}\n:::\n\n```{.r .cell-code}\n#tables\nst_join(bothRegressions, acsRaceIncome) %>%\n  filter(!is.na(raceContext)) %>%\n  group_by(Regression, raceContext) %>%\n  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%\n  st_drop_geometry() %>%\n  spread(raceContext, mean.MAPE) %>%\n  kable(caption = \"Table 5: MAPE by Neighborhood Racial Context\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Table 5: MAPE by Neighborhood Racial Context\n\n|Regression           |Majority Non-White |Majority White |\n|:--------------------|:------------------|:--------------|\n|Baseline Regression  |110%               |81%            |\n|Neighborhood Effects |108%               |80%            |\n\n\n:::\n\n```{.r .cell-code}\nst_join(bothRegressions, acsRaceIncome) %>%\n  filter(!is.na(incomeContext)) %>%\n  group_by(Regression, incomeContext) %>%\n  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%\n  st_drop_geometry() %>%\n  spread(incomeContext, mean.MAPE) %>%\n  kable(caption = \"Table 6: MAPE by Neighborhood Income Context\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Table 6: MAPE by Neighborhood Income Context\n\n|Regression           |High Income |Low Income |\n|:--------------------|:-----------|:----------|\n|Baseline Regression  |84%         |91%        |\n|Neighborhood Effects |83%         |88%        |\n\n\n:::\n:::\n\n\n\n## Discussion\nIn conclusion, our model is effective at predicting the distribution of home sale prices in the area as the pattern of predicted prices matches that of recent known home sale prices. However, it is limited in its ability to generalize across different types of neighborhoods. \n\nWe have many interesting variables which had relationships with salePrice. As expected, distance from the shore correlates negatively with sale price, however the correlation was much weaker than expected because it only seemed to matter for the first mile from water. By contrast, floodInsureType correlated quite strongly with sale price. This feature comes from FEMA's rating of flood risk for different neighborhoods, and unlike our expectation, it was not only based on distance from the shoreline. \n  \nIn general, we found that houses' internal features were the strongest predictors of sale price. In addition, census features such as percent vacancy in a tract, median household income, and travel time to work correlated with sale price. Contrary to our expectations, distance to water, food establishments, businesses, school catchment areas, and park space are less correlated with home sale price. \n\nOur errors were higher than we would like. As discussed in the cross validation section, some houses had a mean average error of hundreds of thousands of dollars. Further, our errors were not distributed evenly, and were higher in low income and minority majority neighborhoods. Indeed, the highest MAPE values on our maps corresponded with the lowest income and lowest sale price neighborhoods. Based on our Moran's I test, however, we were successful at eliminating spatial clustering of errors. In all, our model predicted much better in high income, high observed sale price neighborhoods. This disparity is likely attributable to the fact that we used mainly positive home attributes and neighborhood amenities in our model. If we used more attributes such as poverty rate, race, and renter occupancy rate, our model may have been better at modeling majority-minority and low-income neighborhoods.\n\n\n## Conclusion\nTo conclude, we do not believe that this model is ready for use by Zillow. Its errors are too significant, and its predictions are too uneven between different types of neighborhoods. Moving forward, we will add more features to this model to increase its ability to predict in neighborhoods with varying demographics. Additionally, we will fine tune features to account for non-linear correlations with sale price, such as by creating more categories.\n",
    "supporting": [
      "miami_hedonic_model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}